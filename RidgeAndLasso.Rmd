---
title: "House Price Prediction 2: The Lasso and Ridge Regression"
output:
  word_document: default
  html_document: default
date: "2023-05-18"
---

### Summary of the data set
```{r}
seattle.df <- read.csv('~/Desktop/House_Price_Prediction/Seattle.csv',
                 stringsAsFactors = TRUE)
seattle.df$renovated = as.factor(seattle.df$renovated)
summary(seattle.df)
```

### Splitting data into training and test sets
```{r}
library(ggplot2)
set.seed(1)

# Training and test sets
train = sample(1:nrow(seattle.df), nrow(seattle.df)*0.8) # 80/20 split
test = (-train)
price.test = seattle.df$price[test]

# Dataframes
train.df = data.frame(seattle.df[train,])
test.df = data.frame(seattle.df[test,])
```

#### 4. The Lasso
```{r}
library(glmnet)
x = model.matrix(price ~ . -sqft_lot + I((sqft_lot)), data = seattle.df)[,-1]
y = seattle.df$price
```

We use cross-validation to find the best tuning parameter lambda, then perform the lasso. Coefficients that are shrunk to zero will be effectively removed from the final model.

```{r}
#################
# The Lasso  ####
#################
grid=10^seq(10,-2,length=100)
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)#coefficient plot
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)#CV error plot
bestlam=cv.out$lambda.min #cv.out$lambda.1se
bestlam
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-price.test)^2) #compare to OLS error
sqrt(mean((lasso.pred-price.test)^2))
#refit on the full data set, using the "best" lambda
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:9,]
lasso.coef
lasso.coef[lasso.coef!=0]
```

The best lambda found with 10-fold cross-validation is 248. After performing the lasso with the best lambda, we find that none of the coefficients of the predictors were shrunk to zero. The root mean squared error is 146395.3, which is slightly higher than the error from OLS (144985). 

```{r}
# Best model
lasso.best = glmnet(x, y, alpha = 1, lambda = bestlam)
coef(lasso.best)
```

### Cross-validation metrics: Lasso
```{r}
library(caret)

#specify the cross-validation method
# k-fold CV; k=10
ctrl <- trainControl(method = "cv", number = 10)

#fit a regression model and use k-fold CV to evaluate performance
model <- train(price ~ . -sqft_lot + I((sqft_lot)), data = seattle.df, method = "lasso", trControl = ctrl)

#view summary of k-fold CV               
print(model)
```

### Conclusion: Lasso
The lasso cross-validated RMSE = 145429.0, R2 = 0.4839, and MAE = 110890.1. The lasso performs slightly worse than least squares (RMSE = 144985). Furthermore, the least squares model is simpler with one less predictor.

### Ridge Regression
```{r}
#######################
# Ridge Regression  ###
#######################
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid)
plot(lasso.mod)#coefficient plot
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)#CV error plot
bestlam=cv.out$lambda.min #cv.out$lambda.1se
bestlam
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-price.test)^2) #compare to OLS error
sqrt(mean((ridge.pred-price.test)^2))
#refit on the full data set, using the "best" lambda
out=glmnet(x,y,alpha=0,lambda=grid)
ridge.coef=predict(out,type="coefficients",s=bestlam)[1:9,]
ridge.coef
ridge.coef[ridge.coef!=0]
```

### Cross-validation metrics: Ridge
```{r}
#specify the cross-validation method
# k-fold CV; k=10
ctrl <- trainControl(method = "cv", number = 10)

#fit a regression model and use k-fold CV to evaluate performance
model <- train(price ~ . -sqft_lot + I((sqft_lot)), data = seattle.df, method = "ridge", trControl = ctrl)

#view summary of k-fold CV               
print(model)
```

### Conclusion: Ridge
The ridge regression cross-validated RMSE = 144896.8, R2 = 0.4951, and MAE = 110158.7. The ridge performs better than least squares (RMSE = 144985). Ridge > OLS > Lasso in terms of reducing RMSE.